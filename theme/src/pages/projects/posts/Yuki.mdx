---
layout: '../../../layouts/Post.astro'
title: Yuki
description: This is a blog post on Yuki Project
publishDate: Apr 10, 2023
featuredImage: '../../../assets/images/RPi.jpg'
excerpt: 'Know more about the RPi Project'
---

<code>
import {Button} from '@littlesticks/odyssey-theme-components';
import { Icon } from 'astro-icon';

	<Button customIcon outlined href="https://github.com/ru2saig/yuki">
		<Fragment slot="icon" class="custom-icon__span">
            <slot name="icon">Repo</slot>
			<Icon name="mdi:github" />
		</Fragment>
	</Button>
</code>
<br/>

## How to Build an Emotion Recognition Bot with Raspberry Pi and Google Cloud

Emotion recognition technology is becoming increasingly sophisticated, and it is now possible to build a bot that can detect human emotions and respond accordingly. In this blog post, we will walk through the process of building an emotion recognition bot using a Raspberry Pi, Pi camera, Google Cloud, and OLED screens.
The Basics

![The Front](../../../assets/images/Yuki/Front.jpg)

The bot will consist of three main components:

    * **A Raspberry Pi**: The Raspberry Pi is a small, inexpensive computer that is perfect for this project. It will be responsible for running the software that detects facial expressions and responds with different reactions.
    * **A Pi camera**: The Pi camera will be used to capture images of people's faces. The images will then be sent to Google Cloud for facial expression recognition.
    * **OLED screens**: The OLED screens will be used to display the bot's reactions.

## The Software

The software for the bot will be written in Python. The first step is to install the necessary libraries and modules. We will need the following libraries:

    * **picamera**: This library is used to control the Pi camera.
    * **numpy**: This library is used for mathematical operations.
    * **tensorflow**: This library is used to train and run machine learning models.
    * **google-cloud-vision**: This library is used to interact with the Google Cloud Vision API.

Once the libraries are installed, we can start writing the code. The first step is to initialize the Raspberry Pi camera and OLED screens. Then, we can load the facial expression recognition model from Google Cloud. Finally, we can start a loop that detects facial expressions and responds with different reactions.

The reactions that the bot can display are:

    **Happy**: The bot will wag its tail and smile.
    **Sad**: The bot will put its head down and look sad.
    **Angry**: The bot will bare its teeth and growl.
    **Neutral**: The bot will just sit there and look normal.

![Reaction](../../../assets/images/Yuki/Reaction.jpg)

## The Assembly

Once the software is complete, we can assemble the bot in the acrylic structure. The acrylic structure should be designed to look like a dog's face. The Raspberry Pi, Pi camera, and OLED screens should be mounted inside the structure. The power supply should be connected to the Raspberry Pi.

## The Conclusion

This project is a great way to learn about facial expression recognition, Raspberry Pi, Google Cloud, and OLED screens. The bot can be used as a companion to help people feel better and improve their psychological state. It can also be used for research purposes to study human emotions.

In addition to the basic components and reactions described above, here are some other things you can add to your emotion recognition bot project:

    More emotions: You can train the bot to recognize more emotions, such as surprise, fear, and disgust.
    Different reactions: You can also add different reactions to the bot, such as making different facial expressions, playing different sounds, or saying different words.
    Portability: You can make the bot more portable by using a battery pack to power it. This way, you can take the bot with you wherever you go.
    Speech recognition: You can add speech recognition to the bot so that it can respond to your voice commands. This can make the bot more interactive and user-friendly.

I hope you enjoyed this blog post!